
# LLMTools Developer Documentation

## üìñ Table of Contents
1. [Overview](#overview)
2. [Core Modules](#core-modules)
3. [API Reference](#api-reference)
4. [Configuration](#configuration)
5. [Security Considerations](#security-considerations)

---

## 1Ô∏è‚É£ Overview

`LLMTools` is a modular Swift package designed to integrate **Local and Cloud-based LLMs (Large Language Models)** into iOS/macOS applications. It supports:

‚úî **Local execution with GPU acceleration**  
‚úî **Cloud execution with OpenAI, Anthropic, and custom APIs**  
‚úî **File system access (secure by default)**  
‚úî **Secure tool execution**  
‚úî **Fine-tuning and structured data extraction**  

---

## 2Ô∏è‚É£ Core Modules

### **1. `LocalLLMProcessor.swift`**
- Loads and executes local LLM models using **Apple‚Äôs MLX framework**.
- Supports **GPU acceleration** for faster inference.

### **2. `CloudLLMClient.swift`**
- Connects to OpenAI, Anthropic, and other cloud-based LLMs.
- Supports **streaming responses**.

### **3. `ModelDownloader.swift`**
- Downloads models from **Hugging Face** and **custom URLs**.

### **4. `ToolManager.swift`**
- Manages AI-driven **external tool execution**.

### **5. `OSCommandExecutor.swift`**
- Allows AI to run **system commands** with **security restrictions**.

### **6. `FileSystemManager.swift`**
- Controls AI-driven **file system operations** within a secure directory.

### **7. `SecureStorage.swift`**
- **Encrypts and stores API keys** securely using AES-256.

---

## 3Ô∏è‚É£ API Reference

### **üìå `LocalLLMProcessor`**

#### **Function: `loadModel(modelPath: String, useGPU: Bool)`**
- **Description:** Loads a local LLM model into memory.
- **Inputs:**  
  - `modelPath: String` ‚Äì The file path to the model.  
  - `useGPU: Bool` ‚Äì Whether to enable GPU acceleration.  
- **Output:** None  

üîπ **Example Usage:**  
```swift
LocalLLMProcessor.shared.loadModel(modelPath: "/models/gpt4.gguf", useGPU: true)
```

---

### **üìå `CloudLLMClient`**

#### **Function: `callOpenAI(prompt: String, streaming: Bool, completion: @escaping (String) -> Void)`**
- **Description:** Calls OpenAI‚Äôs API with a given prompt.
- **Inputs:**  
  - `prompt: String` ‚Äì The input text to send.  
  - `streaming: Bool` ‚Äì Whether to use real-time streaming.  
  - `completion: @escaping (String) -> Void` ‚Äì Callback function with the response.  
- **Output:** None (response is returned asynchronously).  

üîπ **Example Usage:**  
```swift
CloudLLMClient.shared.callOpenAI(prompt: "What is AI?", streaming: false) { response in
    print(response)
}
```

---

### **üìå `ModelDownloader`**

#### **Function: `downloadModel(provider: ModelProvider, destinationPath: String, completion: @escaping (String) -> Void)`**
- **Description:** Downloads a model from Hugging Face or a custom provider.
- **Inputs:**  
  - `provider: ModelProvider` ‚Äì Hugging Face or Custom URL.  
  - `destinationPath: String` ‚Äì Where to save the model.  
  - `completion: @escaping (String) -> Void` ‚Äì Callback when download finishes.  
- **Output:** None (completion block contains status).  

üîπ **Example Usage:**  
```swift
ModelDownloader.shared.downloadModel(provider: .huggingFace(modelRepo: "meta-llama/Llama-2-7b"), 
                                     destinationPath: "/models/Llama-2-7b.gguf") { result in
    print(result)
}
```

---

### **üìå `SecureStorage`**

#### **Function: `saveAPIKey(service: String, apiKey: String)`**
- **Description:** Encrypts and securely stores an API key.
- **Inputs:**  
  - `service: String` ‚Äì The name of the API service.  
  - `apiKey: String` ‚Äì The API key to store.  
- **Output:** None  

üîπ **Example Usage:**  
```swift
SecureStorage.saveAPIKey(service: "OpenAI", apiKey: "sk-xxxxxxx")
```

#### **Function: `getAPIKey(service: String) -> String?`**
- **Description:** Retrieves a previously stored API key.
- **Inputs:**  
  - `service: String` ‚Äì The name of the API service.  
- **Output:** `String?` (The decrypted API key or `nil` if not found).  

üîπ **Example Usage:**  
```swift
if let openAIKey = SecureStorage.getAPIKey(service: "OpenAI") {
    print("Retrieved API Key: \(openAIKey)")
}
```

---

## 4Ô∏è‚É£ Configuration

### **Environment Variables**
To store API keys securely, set them as environment variables in macOS/Linux:

```bash
export OPENAI_API_KEY="sk-xxxxxxx"
```

Retrieve them in Swift:
```swift
let apiKey = ProcessInfo.processInfo.environment["OPENAI_API_KEY"]
```

---

## 5Ô∏è‚É£ Security Considerations

‚úî **Restrict OS execution (`OSCommandExecutor.swift`)**  
‚úî **Limit file access (`FileSystemManager.swift`)**  
‚úî **Never log API keys (`SecureStorage.swift`)**  
‚úî **Use GPU acceleration for secure local processing**  

---

## üîú Future Enhancements

‚úî **Add support for additional LLM providers (e.g., Cohere, Meta AI).**  
‚úî **Enhance real-time streaming capabilities.**  
‚úî **Improve local model inference with MLX optimizations.**  

---

### üìå Final Notes
This documentation provides an **in-depth reference for `LLMTools`**, covering **functionality, security, and best practices**.

